
import { GoogleGenAI, Type } from "@google/genai";
import { GeminiConfig, Attachment, AnalysisTemplate, ChatMessage } from "../types";

export const performProjectAnalysis = async (
  projectContext: string,
  userPrompt: string,
  onStream?: (chunk: string) => void,
  diffContext?: string,
  userConfig?: GeminiConfig,
  projectSpec?: string,
  attachments: Attachment[] = [],
  history: ChatMessage[] = []
): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  const modelName = userConfig?.model || 'gemini-3-pro-preview';
  const useThinking = userConfig?.useThinking !== false;
  const useSearch = userConfig?.useSearch === true;

  // Ajuste de budget: Modelos Pro suportam mais tokens de pensamento
  const budget = modelName.includes('pro') ? 32768 : 24576;

  // Constru√ß√£o do System Prompt Robusto
  const systemPrompt = `
    Voc√™ √© um Arquiteto de Software S√™nior e Revisor de C√≥digo Elite (Project Unifier AI).
    
    [[CONTEXTO DO PROJETO]]
    O usu√°rio carregou os seguintes arquivos do projeto para an√°lise:
    ---
    ${projectContext}
    ---

    ${projectSpec ? `[[SPECIFICATION / BLUEPRINT]]\nRegras de arquitetura definidas:\n${projectSpec}\n` : ''}
    ${diffContext ? `[[GIT DIFF / MUDAN√áAS]]\nO usu√°rio est√° analisando estas mudan√ßas:\n${diffContext}\n` : ''}

    DIRETRIZES:
    1. Responda com precis√£o t√©cnica, citando arquivos e trechos de c√≥digo quando relevante.
    2. Se houver um Blueprint, siga-o estritamente.
    3. Use Markdown para formatar a resposta (blocos de c√≥digo, negrito, listas).
    4. Seja direto e evite pre√¢mbulos desnecess√°rios.
    ${useSearch ? '5. Voc√™ tem acesso √† Busca do Google. Use-a para encontrar documenta√ß√£o recente, vers√µes de bibliotecas e solu√ß√µes para erros atuais.' : ''}
  `;

  const config: any = {
    temperature: 0.7,
    systemInstruction: systemPrompt,
  };

  // Configura√ß√£o de Tools
  if (useSearch) {
    config.tools = [{ googleSearch: {} }];
    // Google Search n√£o pode ser usado junto com Thinking Mode em algumas vers√µes, 
    // mas o Gemini 3.0 geralmente permite. Se houver conflito, a API retornar√° erro.
    // Por seguran√ßa, se busca estiver ativa, podemos desativar o thinking ou mant√™-lo se suportado.
    // Vamos manter ambos ativos conforme a config do usu√°rio, assumindo suporte do modelo 3.0.
  }
  
  if (useThinking) {
    config.thinkingConfig = { thinkingBudget: budget };
  }

  // Mapeamento do hist√≥rico para o formato da API
  const historyContents = history.map(msg => {
    const parts: any[] = [{ text: msg.text }];
    if (msg.role === 'user' && msg.attachments) {
      msg.attachments.forEach(att => {
        parts.push({
          inlineData: {
            data: att.data,
            mimeType: att.mimeType
          }
        });
      });
    }
    return {
      role: msg.role,
      parts
    };
  });

  // Constru√ß√£o da mensagem atual
  const currentParts: any[] = [{ text: userPrompt }];
  attachments.forEach(att => {
    currentParts.push({
      inlineData: {
        data: att.data,
        mimeType: att.mimeType
      }
    });
  });

  const contents = [
    ...historyContents,
    { role: 'user', parts: currentParts }
  ];

  try {
    if (onStream) {
      const responseStream = await ai.models.generateContentStream({
        model: modelName,
        contents,
        config
      });

      let fullText = '';
      let groundingMetadata: any = null;

      for await (const chunk of responseStream) {
        const text = chunk.text;
        if (text) {
          fullText += text;
          onStream(text);
        }
        
        // Captura metadados de aterramento (Search)
        if (chunk.candidates?.[0]?.groundingMetadata) {
          groundingMetadata = chunk.candidates[0].groundingMetadata;
        }
      }

      // Se houver dados de busca, formatar e anexar ao final
      if (groundingMetadata?.groundingChunks) {
        const sources = groundingMetadata.groundingChunks
          .map((c: any) => c.web ? `- [${c.web.title}](${c.web.uri})` : null)
          .filter(Boolean);

        if (sources.length > 0) {
          const sourcesMd = `\n\n---\n### üåê Fontes da Pesquisa\n${sources.join('\n')}`;
          fullText += sourcesMd;
          onStream(sourcesMd);
        }
      }

      return fullText;
    } else {
      const response = await ai.models.generateContent({
        model: modelName,
        contents,
        config
      });
      
      let text = response.text || "O modelo processou a solicita√ß√£o mas n√£o retornou texto.";
      
      // Processamento de Grounding para chamadas n√£o-stream
      const groundingMetadata = response.candidates?.[0]?.groundingMetadata;
      if (groundingMetadata?.groundingChunks) {
        const sources = groundingMetadata.groundingChunks
          .map((c: any) => c.web ? `- [${c.web.title}](${c.web.uri})` : null)
          .filter(Boolean);

        if (sources.length > 0) {
          text += `\n\n---\n### üåê Fontes da Pesquisa\n${sources.join('\n')}`;
        }
      }

      return text;
    }
  } catch (error: any) {
    console.error("Gemini API Error:", error);
    throw new Error(`Erro na IA: ${error.message}`);
  }
};

export const generateProjectBlueprint = async (
  projectContext: string,
  userConfig?: GeminiConfig
): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  // Para blueprints, usamos sempre o modelo Pro com thinking alto
  const prompt = `
    Analise profundamente o c√≥digo fonte fornecido e gere um "Technical Blueprint" (Especifica√ß√£o T√©cnica).
    
    Estrutura da Resposta (Markdown):
    # Blueprint do Sistema
    ## 1. Vis√£o Geral & Dom√≠nio
    Resumo do prop√≥sito do software e principais entidades.
    
    ## 2. Arquitetura de Dados
    Como os dados fluem? Principais stores, bancos ou estados globais.
    
    ## 3. Stack & Padr√µes
    Linguagens, frameworks e patterns identificados (ex: MVVM, Repository, Hooks).
    
    ## 4. Pontos Cr√≠ticos
    √Åreas que requerem aten√ß√£o especial (seguran√ßa, performance, d√≠vida t√©cnica).
    
    CONTEXTO DO C√ìDIGO:
    ${projectContext.slice(0, 800000)} // Limite de seguran√ßa
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [{ parts: [{ text: prompt }] }],
      config: { 
        temperature: 0.2,
        thinkingConfig: { thinkingBudget: 16000 } 
      }
    });
    return response.text || "N√£o foi poss√≠vel gerar o blueprint.";
  } catch (error: any) {
    throw new Error("Falha ao gerar Blueprint: " + error.message);
  }
};

export const generateAdaptiveTemplates = async (
  projectContext: string
): Promise<AnalysisTemplate[]> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  const contextSnippet = projectContext.slice(0, 30000); 

  const prompt = `
    Com base neste c√≥digo, crie 3 prompts de an√°lise customizados √∫teis para um desenvolvedor.
    Retorne APENAS um JSON Array puro.
    Exemplo Schema: [{ "id": "...", "name": "...", "description": "...", "prompt": "...", "icon": "emoji" }]
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: [{ parts: [{ text: `C√ìDIGO:\n${contextSnippet}\n\n${prompt}` }] }],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              id: { type: Type.STRING },
              name: { type: Type.STRING },
              description: { type: Type.STRING },
              prompt: { type: Type.STRING },
              icon: { type: Type.STRING }
            },
            required: ["id", "name", "description", "prompt", "icon"]
          }
        }
      }
    });

    return JSON.parse(response.text || "[]") as AnalysisTemplate[];
  } catch (error) {
    console.warn("Erro templates adaptativos:", error);
    return [];
  }
};

export const generateSmartSuggestions = async (
  projectContext: string
): Promise<string[]> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  const contextSnippet = projectContext.slice(0, 50000); 

  const prompt = `
    Voc√™ √© um Tech Lead analisando este c√≥digo.
    Gere 4 perguntas ou comandos curtos (max 10 palavras) que um desenvolvedor deveria fazer para auditar ou melhorar este projeto.
    Foque em: Arquitetura, Bugs Potenciais, Seguran√ßa ou Performance.
    Exemplos: "Analise o gerenciamento de estado", "Busque vazamento de mem√≥ria nos hooks", "Audite a seguran√ßa das rotas de API".
    
    Retorne APENAS um JSON Array de strings. Ex: ["Pergunta 1", "Pergunta 2"]
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: [{ parts: [{ text: `CONTEXTO (Snippet):\n${contextSnippet}\n\n${prompt}` }] }],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: { type: Type.STRING }
        }
      }
    });

    return JSON.parse(response.text || "[]") as string[];
  } catch (error) {
    console.warn("Erro ao gerar sugest√µes inteligentes:", error);
    return [
      "Explique a arquitetura principal",
      "Identifique pontos de falha",
      "Sugira melhorias de performance",
      "Crie diagramas do sistema"
    ]; 
  }
};
